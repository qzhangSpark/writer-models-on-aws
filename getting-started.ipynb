{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b48c4ff-eba3-40af-8430-fe5647ef14e0",
   "metadata": {},
   "source": [
    "# Getting Started"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ac0d3a-c089-4ea3-b104-754de009bb19",
   "metadata": {},
   "source": [
    "Writer's Palmyra foundation models on Amazon Bedrock include Palmyra X4 and Palmyra X5. Palmyra X5 is Writer's most advanced model, purpose-built for building and scaling AI agents across the enterprise. It delivers industry-leading speed and efficiency on context windows up to 1 million tokens, powered by a novel transformer architecture and hybrid attention mechanisms. This enables faster inference and expanded memory for processing large volumes of enterprise data and tool calls, critical for scaling AI agents. With adaptive reasoning to dynamically adjust strategy based on context, Palmyra X5 also supports code generation, structured outputs, and over 30 languages.\n",
    "\n",
    "Top ranked on Stanford HELM, Palmyra X4 achieves superior performance on complex tasks and agentic workflows. It combines a 128K token context window with a suite of capabilities, including advanced reasoning, tool calling, LLM delegation, built-in RAG, code generation, structured outputs, multi-modality, and multilingual support. Using enterprise-specific tools that extend the model's ability to take action, Palmyra X4 allows developers to build apps and agents that update systems, perform transactions, send emails, trigger workflows, and more.\n",
    "\n",
    "This notebook shows you how to invoke Writer Palmyra X5 using Amazon Bedrock APIs. \n",
    "\n",
    "## Prerequisite: \n",
    "- Writer models are currently supported in **us-west-2** region. Please make sure this notebook runs in us-west-2 (Oregon) region.\n",
    "- You invoke Writer models using their Inference profile ID or Inference profile ARN. Go to **Amazon Bedrock Console**. Under **Inference and Assessment**, select **Cross-region inference**. You see a list of Inference profiles. In **Find inference profiles**, search 'Palmyra X5'. The inference profile for US Palmyra X5 will be shown. Copy the **Inference profile ID** (us.writer.palmyra-x5-v1:0) or **Inference profile ARN** (arn:aws:bedrock:us-west-2:YOUR AWS ACCOUNT ID:inference-profile/us.writer.palmyra-x5-v1:0) as model id for invocations. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9349786a-9e9a-430c-beb9-bc225b4a118b",
   "metadata": {},
   "source": [
    "## Import the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e211c581-02ce-42b2-9875-754de5a03209",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "import botocore\n",
    "from botocore.exceptions import ClientError\n",
    "from IPython.display import display, Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7301379a-174e-4886-82f9-d3938d946e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function to display model responses in a more readable format\n",
    "def display_response(response, model_name=None):\n",
    "    if model_name:\n",
    "        display(Markdown(f\"### Response from {model_name}\"))\n",
    "    display(Markdown(response))\n",
    "    print(\"\\n\" + \"-\"*80 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5de28a42-5181-49ad-81e1-bacd07dcd0b1",
   "metadata": {},
   "source": [
    "## Select the Writer Palmyra X5 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8800f886-c0cf-4e1a-897f-0794a7bd5ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "bedrock = boto3.client(\"bedrock-runtime\", region_name=\"us-west-2\")\n",
    "model_id = \"us.writer.palmyra-x5-v1:0\"\n",
    "# model_id = \"arn:aws:bedrock:us-west-2:YOUR AWS ACCOUNT ID:inference-profile/us.writer.palmyra-x5-v1:0\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "988b21f7-cb0a-4d23-8a01-caf0e74294d4",
   "metadata": {},
   "source": [
    "## Invoke the Writer model using invoke_model API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7252c885-e488-47ce-bfdd-cc7d512d67d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Response from Writer Palmyra X5 (Invoke model API)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Quantum computing is a new way of processing information that's different from the classical computers we use today. To understand it, let's start with how classical computers work.\n",
       "\n",
       "**Classical Computing**\n",
       "\n",
       "Classical computers use \"bits\" to store and process information. A bit is like a coin that can be either heads (0) or tails (1). These bits are used to perform calculations and operations, one step at a time. Think of it like a long, sequential process where each step depends on the previous one.\n",
       "\n",
       "**Quantum Computing**\n",
       "\n",
       "Quantum computers use \"qubits\" (quantum bits), which are like special coins that can be both heads AND tails at the same time. This property, called superposition, allows qubits to process multiple possibilities simultaneously. It's like being able to flip multiple coins at once and having them all land on both heads and tails simultaneously!\n",
       "\n",
       "Qubits also have another property called entanglement, where they're connected in a way that lets them affect each other, even if they're separated. This enables quantum computers to perform many calculations in parallel, making them potentially much faster than classical computers for certain tasks.\n",
       "\n",
       "**How Quantum Computing Works**\n",
       "\n",
       "Imagine you have a combination lock with many numbers. A classical computer would try each number one by one, sequentially, until it finds the correct combination. A quantum computer, on the other hand, can try all possible combinations simultaneously, thanks to the properties of qubits. This means that, for certain problems, a quantum computer can find the solution much faster than a classical computer.\n",
       "\n",
       "**Potential Applications**\n",
       "\n",
       "Quantum computing has the potential to revolutionize fields like:\n",
       "\n",
       "1. **Cryptography**: Quantum computers can break certain types of encryption, but they can also be used to create unbreakable encryption methods.\n",
       "2. **Optimization**: Quantum computers can quickly solve complex optimization problems, which could lead to breakthroughs in fields like logistics, finance, and energy management.\n",
       "3. **Simulation**: Quantum computers can simulate complex systems, like molecules and materials, which could lead to new discoveries in chemistry and materials science.\n",
       "\n",
       "**Challenges and Limitations**\n",
       "\n",
       "While quantum computing is a promising technology, it's still in its early stages. Building and maintaining quantum computers is challenging due to the fragile nature of qubits and the need for precise control over their behavior.\n",
       "\n",
       "In summary, quantum computing is a new paradigm that uses the strange and fascinating properties of quantum mechanics to process information in ways that classical computers can't. While it's still an emerging field, it has the potential to solve complex problems that are currently unsolvable or require an unfeasible amount of time to solve classically."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Format the request payload using the model's native structure.\n",
    "native_request = {\n",
    "    \"temperature\": 1,\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Explain quantum computing in simple terms.\",\n",
    "        }\n",
    "    ],\n",
    "}\n",
    "\n",
    "# Convert the native request to JSON.\n",
    "request = json.dumps(native_request)\n",
    "\n",
    "try:\n",
    "    # Invoke the model with the request.\n",
    "    response = bedrock.invoke_model(modelId=model_id, body=request) \n",
    "except (ClientError, Exception) as e:\n",
    "    print(f\"ERROR: Can't invoke '{model_id}'. Reason: {e}\")\n",
    "    exit(1)\n",
    "\n",
    "# Decode the response body.\n",
    "model_response = json.loads(response[\"body\"].read())\n",
    "\n",
    "# Extract and print the response text.\n",
    "response_text = model_response['choices'][0]['message']['content']\n",
    "# print(response_text)\n",
    "display_response(response_text, \"Writer Palmyra X5 (Invoke model API)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e283ace-24a5-4adc-adec-c450435905de",
   "metadata": {},
   "source": [
    "## Invoke the Writer model using Converse API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d17ed646-8702-44d0-a136-c1fac64287a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Response from Writer Palmyra X5 (Converse API)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Amazon Bedrock is a fully managed service offered by AWS that allows users to build and scale generative AI applications. It provides access to a variety of foundation models (FMs) from top AI companies, including AI21 Labs, Anthropic, Cohere, Meta, Stability AI, and Amazon. \n",
       "\n",
       "With Amazon Bedrock, users can easily experiment with and evaluate different FMs for their specific use case, fine-tune these models with their own data, and integrate them into their applications using a straightforward API. The service also provides features to help users build generative AI applications securely and responsibly.\n",
       "\n",
       "Some key features of Amazon Bedrock include:\n",
       "\n",
       "1. **Access to multiple FMs**: Users can choose from a variety of FMs, each with its own strengths and capabilities.\n",
       "2. **Fine-tuning**: Users can fine-tune FMs with their own data to improve performance on specific tasks.\n",
       "3. **API integration**: FMs can be integrated into applications using a simple API.\n",
       "4. **Security and governance**: Amazon Bedrock provides features to help users build generative AI applications securely and responsibly.\n",
       "\n",
       "The benefits of using Amazon Bedrock include:\n",
       "\n",
       "1. **Faster development**: Users can quickly build and deploy generative AI applications.\n",
       "2. **Improved performance**: Fine-tuning FMs with custom data can improve performance on specific tasks.\n",
       "3. **Increased flexibility**: Users can choose from a variety of FMs and integrate them into their applications.\n",
       "\n",
       "Overall, Amazon Bedrock is a powerful tool for building and scaling generative AI applications, and it provides a range of features and benefits that can help users achieve their goals."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a converse request \n",
    "converse_request = {\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"text\": \"Talk about Amazon Bedrock.\"\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ],\n",
    "    \"inferenceConfig\": {\n",
    "        \"temperature\": 0.4,\n",
    "        \"topP\": 0.9,\n",
    "        \"maxTokens\": 500\n",
    "    }\n",
    "}\n",
    "\n",
    "# Call the Writer model with Converse API\n",
    "try:\n",
    "    response = bedrock.converse(\n",
    "        modelId=model_id,\n",
    "        messages=converse_request[\"messages\"],\n",
    "        inferenceConfig=converse_request[\"inferenceConfig\"]\n",
    "    )\n",
    "    \n",
    "    # Extract the model's response\n",
    "    writer_converse_response = response[\"output\"][\"message\"][\"content\"][0][\"text\"]\n",
    "    display_response(writer_converse_response, \"Writer Palmyra X5 (Converse API)\")\n",
    "except botocore.exceptions.ClientError as error:\n",
    "    if error.response['Error']['Code'] == 'AccessDeniedException':\n",
    "        print(f\"\\x1b[41m{error.response['Error']['Code']}: {error.response['Error']['Message']}\\x1b[0m\")\n",
    "        print(\"Please ensure you have the necessary permissions for Amazon Bedrock.\")\n",
    "    else:\n",
    "        raise error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae1abe8-de59-4776-a5d8-5d22f5609abd",
   "metadata": {},
   "source": [
    "## Streaming the Writer model responses using ConverseStream API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "616334be-966a-4981-85bc-4168519e2873",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of streaming with Converse API\n",
    "def stream_converse(model_id, messages, inference_config=None):\n",
    "    if inference_config is None:\n",
    "        inference_config = {}\n",
    "    \n",
    "    print(\"Streaming response (chunks will appear as they are received):\\n\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    full_response = \"\"\n",
    "    \n",
    "    try:\n",
    "        response = bedrock.converse_stream(\n",
    "            modelId=model_id,\n",
    "            messages=messages,\n",
    "            inferenceConfig=inference_config\n",
    "        )\n",
    "        response_stream = response.get('stream')\n",
    "        if response_stream:\n",
    "            for event in response_stream:\n",
    "\n",
    "                if 'messageStart' in event:\n",
    "                    print(f\"\\nRole: {event['messageStart']['role']}\")\n",
    "\n",
    "                if 'contentBlockDelta' in event:\n",
    "                    print(event['contentBlockDelta']['delta']['text'], end=\"\")\n",
    "\n",
    "                if 'messageStop' in event:\n",
    "                    print(f\"\\nStop reason: {event['messageStop']['stopReason']}\")\n",
    "\n",
    "                if 'metadata' in event:\n",
    "                    metadata = event['metadata']\n",
    "                    if 'usage' in metadata:\n",
    "                        print(\"\\nToken usage\")\n",
    "                        print(f\"Input tokens: {metadata['usage']['inputTokens']}\")\n",
    "                        print(\n",
    "                            f\":Output tokens: {metadata['usage']['outputTokens']}\")\n",
    "                        print(f\":Total tokens: {metadata['usage']['totalTokens']}\")\n",
    "                    if 'metrics' in event['metadata']:\n",
    "                        print(\n",
    "                            f\"Latency: {metadata['metrics']['latencyMs']} milliseconds\")\n",
    "\n",
    "                \n",
    "            print(\"\\n\" + \"-\" * 80)\n",
    "        return full_response\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error in streaming: {str(e)}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f2e5b44b-cb18-4199-b9d2-f56427392605",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Streaming response (chunks will appear as they are received):\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Role: assistant\n",
      "AI agents, also known as intelligent agents, are computer programs or systems that use artificial intelligence (AI) to perform tasks that typically require human intelligence, such as reasoning, problem-solving, and learning. These agents can be designed to operate autonomously, making decisions and taking actions based on their programming, data, and environment.\n",
      "\n",
      "**Types of AI Agents:**\n",
      "\n",
      "1. **Simple Reflex Agents**: React to the current state of the environment without considering future consequences.\n",
      "2. **Model-Based Reflex Agents**: Maintain an internal model of the environment and use it to make decisions.\n",
      "3. **Goal-Based Agents**: Have specific goals and can plan to achieve them.\n",
      "4. **Utility-Based Agents**: Make decisions based on a utility function that estimates the desirability of different outcomes.\n",
      "5. **Learning Agents**: Can learn from experience and adapt to new situations.\n",
      "\n",
      "**Benefits of AI Agents:**\n",
      "\n",
      "1. **Automation**: AI agents can automate repetitive, mundane, and time-consuming tasks, freeing up human resources for more strategic and creative work.\n",
      "2. **Improved Efficiency**: AI agents can process vast amounts of data quickly and accurately, making them ideal for tasks that require speed and precision.\n",
      "3. **Enhanced Decision-Making**: AI agents can analyze data, identify patterns, and make informed decisions, reducing the risk of human bias and error.\n",
      "4. **Personalization**: AI agents can be designed to provide personalized experiences for users, such as tailored recommendations or customer support.\n",
      "5. **Scalability**: AI agents can handle a large volume of requests and interactions, making them suitable for applications with high traffic or demand.\n",
      "6. **24/7 Operation**: AI agents can operate around the clock, providing continuous support and service without breaks or downtime.\n",
      "7. **Cost Savings**: AI agents can reduce labor costs and minimize the need for human intervention, resulting in significant cost savings.\n",
      "8. **Improved Customer Experience**: AI agents can provide quick and effective support, improving customer satisfaction and loyalty.\n",
      "\n",
      "**Real-World Applications of AI Agents:**\n",
      "\n",
      "1. **Virtual Assistants**: Virtual assistants like Siri, Google Assistant, and Alexa use AI agents to understand voice commands and respond accordingly.\n",
      "2. **Chatbots**: Chatbots are AI agents that provide customer support and answer frequently asked questions.\n",
      "3. **Recommendation Systems**: Online retailers use AI agents to recommend products based on user behavior and preferences.\n",
      "4. **Predictive Maintenance**: AI agents can predict equipment failures and schedule maintenance, reducing downtime and increasing overall efficiency.\n",
      "5. **Healthcare**: AI agents are being used in healthcare to diagnose diseases, develop personalized treatment plans, and streamline clinical workflows.\n",
      "\n",
      "In summary, AI agents are powerful tools that can automate tasks, improve efficiency, and enhance decision-making. Their benefits are numerous, and their applications are diverse, ranging from virtual assistants to predictive maintenance and healthcare.\n",
      "Stop reason: end_turn\n",
      "\n",
      "Token usage\n",
      "Input tokens: 38\n",
      ":Output tokens: 568\n",
      ":Total tokens: 606\n",
      "Latency: 5438 milliseconds\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "streaming_request = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\n",
    "                \"text\": \"what are AI agents? Explain its benefits\"\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "]\n",
    "\n",
    "# Only run this when you're ready to see streaming output\n",
    "streamed_response = stream_converse(\n",
    "    model_id, \n",
    "    streaming_request, \n",
    "    inference_config={\"temperature\": 0.4, \"maxTokens\": 1000}\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
